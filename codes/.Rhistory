install.packages("Rcpp")
install.packages("RcppArmadillo")
install.packages("dplyr")
install.packages("data.table")
install.packages("data.table")
install.packages("tidyr")
install.packages("readr")
install.packages("ggplot2")
install.packages("tidyverse")
print("Olá Mundo")
print("Olá Mundo")
print("Olá, tudo bem ?")
print("Estou bem sim")
print("Olá Mundo")
print("Olá, tudo bem ?")
print('Estou bem sim')
print('Estou bem sim')
print('Estou bem sim')
print('Estou bem sim')
mes_numero <- c(1,2,3,4,5,6,7,8,9,10,11,12)
mes_nome <- c("janeiro","fevereiro","mar?o","abril","maio","junho","julho",
"agosto","setembro","outubro","novembro","dezembro")
ano <- c(2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021)
data.frame(mes_numero,mes_nome,ano)
data_frame <- data.frame(mes_numero,mes_nome,ano)
View(data_frame)
# Data Frames pertencentes ao R
df <- mtcars
df
View(mtcars)
df2 <- airquality
df2
View(airquality)
?airquality
?datasets
df3 = iris
View(df3)
nrow(df3)
ncol(df3)
dim(df3)
summary(df3)
nome <- c("Luciano","Pedro","Joyce", "Maria")
idade <- c(46, 38, 27, 29)
curso <- c("Estat?stica", "Linguagem R", "Redes Neurais", "Python")
lista <- list(nome, idade, curso)
print(lista)
# objeto da lista, basta colocar entre colchetes.
lista[1]
# nomeando termos da lista
lista2 <- list(nome = c("Luciano","Pedro","Joyce", "Maria"),
idade = c(46, 38, 27, 29),
curso = c("Estat?stica","Linguagem R","Redes Neurais","Python"))
lista2
# BAIXAR PACOTES, CASO ELES AINDA N?O ESTEJAM BAIXADOS
install.packages("argo")
# CARREGAR PACOTES
library(argo)
??argo
# BAIXAR PACOTES, CASO ELES AINDA N?O ESTEJAM BAIXADOS
if(!require(argo)) install.packages("argo")
# CARREGAR PACOTES
library(argo)
# REMOVER PACOTES
remove.packages("argo")
load("~/IC/bbcsport/mcmc_output/mcmc_chain.Rdata")
View(chain)
View(chain)
View(chain)
names(chain)
View(chain)
transform <- function(data_mat
){
D = max(data_mat[, 2])
w = rep( list(NULL), D)
for (d in 1:D){
doc_d = data_mat[which(data_mat$doc == d), c(1,3)]
print(paste('d = ', d))
for (i in 1:nrow(doc_d) ){
w[[d]] = c(w[[d]], rep( doc_d$word[i] - 1, doc_d$freq[i]) )
}
}
return(w)
}
DIC_LDA = function(data_mat, chain, mcmc_ind){
# extracts marginal chains
beta_chain = chain$beta
chain$beta = 0
theta_chain = chain$theta
chain$theta = 0
w = transform(data)
M = length(mcmc_ind)
D = max(data_mat$doc)
for (d in 1:D){
w[[d]] = w[[d]] + 1
}
print("Calculating mean D(theta) ...")
mean_D_theta = 0
for (m in mcmc_ind){
print(m)
for (d in 1:D){
Nd = length(w[[d]])
for( n in 1:Nd){
mean_D_theta = mean_D_theta + log(beta_chain[,w[[d]][n],m] %*% theta_chain[d,,m])
}
}
}
mean_D_theta = -2*mean_D_theta/M
beta_barra = apply(X = beta_chain,FUN = mean, MARGIN = c(1,2))
theta_barra = apply(X = theta_chain,FUN = mean, MARGIN = c(1,2))
print("Calculating D( mean(theta) ) ...")
D_theta_mean = 0
for (d in 1:D){
Nd = length(w[[d]])
for (n in 1:Nd){
D_theta_mean = D_theta_mean + log(beta_barra[,w[[d]][n]]%*%theta_barra[d,])
}
}
D_theta_mean = -2 * D_theta_mean
p_D = mean_D_theta - D_theta_mean
DIC = p_D + mean_D_theta
print("Done.")
return( DIC )
}
rm(list=ls(all=TRUE))
#memory.limit(size = 56000)
require(gtools)
require(Rcpp)
require(RcppArmadillo)
setwd("C:/Users/joaov/Documents/IC")
data_mat = read.table("./neurips/data/docword_nips.txt", skip = 3)
head(data_mat[,c(2,1,3)])
str(data_mat)
data_mat = data_mat[,c(2,1,3)]
colnames(data_mat) = c("word", "doc", "freq")
data_mat = data_mat[-1,]
data = data_mat[order(data_mat[,2], decreasing=FALSE), ]
data_mat = as.matrix(data_mat)
# Defining variables
K = 10
D = max(data_mat$doc)
rm(list=ls(all=TRUE))
#memory.limit(size = 56000)
require(gtools)
require(Rcpp)
require(RcppArmadillo)
setwd("C:/Users/joaov/Documents/IC")
data_mat = read.table("./neurips/data/docword_nips.txt", skip = 3)
head(data_mat[,c(2,1,3)])
str(data_mat)
data_mat = data_mat[,c(2,1,3)]
colnames(data_mat) = c("word", "doc", "freq")
data_mat = data_mat[-1,]
data = data_mat[order(data_mat[,2], decreasing=FALSE), ]
data_mat = as.matrix(data_mat)
# Defining variables
K = 10
D = max(data_mat$doc)
rm(list=ls(all=TRUE))
#memory.limit(size = 56000)
require(gtools)
require(Rcpp)
require(RcppArmadillo)
# set working directory to the location of the main github folder in local machine
setwd("C:/Users/joaov/Documents/IC")
data_mat = read.table("./neurips/data/docword_nips.txt", skip = 3)
colnames(data_mat) = c("doc", "word", "freq")
head(data_mat[,c(2,1,3)])
str(data_mat)
data_mat = data_mat[,c(2,1,3)]
# data_mat = data_mat[-1,] <-------- NAO DELETE A PRIMEIRA LINHA. ELA PODE PERMANECER SEM PROBLEMAS
data = data_mat[order(data_mat[,2], decreasing=FALSE), ]
setwd("./codes")
source("utils.R")
sourceCpp("./mcmc_function.cpp")
source("./mcmc_bbc_function.R")
w = transform(data)
# for k = 10 is done
# for k = 15 is in done
# for k = 20 is in fault
# comparar tempo computacional com o pacote lda
start = Sys.time()
mcmc_cpp( data = as.matrix(data), w , K = 20, n_iter = 10, save_it = 5 )
rm(list=ls(all=TRUE))
#memory.limit(size = 56000)
require(gtools)
require(Rcpp)
require(RcppArmadillo)
setwd("C:/Users/joaov/Documents/IC")
data_mat = read.table("./neurips/data/docword_nips.txt", skip = 3)
head(data_mat[,c(2,1,3)])
str(data_mat)
data_mat = data_mat[,c(2,1,3)]
colnames(data_mat) = c("word", "doc", "freq")
data_mat = data_mat[-1,]
data = data_mat[order(data_mat[,2], decreasing=FALSE), ]
data_mat = as.matrix(data_mat)
# Defining variables
K = 10
D = max(data_mat$doc)
rm(list=ls(all=TRUE))
#memory.limit(size = 56000)
require(gtools)
require(Rcpp)
require(RcppArmadillo)
setwd("C:/Users/joaov/Documents/IC")
data_mat = read.table("./neurips/data/docword_nips.txt", skip = 3)
head(data_mat[,c(2,1,3)])
str(data_mat)
data_mat = data_mat[,c(2,1,3)]
colnames(data_mat) = c("word", "doc", "freq")
data_mat = data_mat[-1,]
data = data_mat[order(data_mat[,2], decreasing=FALSE), ]
data_mat = as.matrix(data_mat)
# load mcmc chain
load(file = "./neurips/mcmc_output/mcmc_chain_10.Rdata")
# Defining variables
K = 10
D = max(data_mat$doc)
rm(list=ls(all=TRUE))
#memory.limit(size = 56000)
require(gtools)
require(Rcpp)
require(RcppArmadillo)
setwd("C:/Users/joaov/Documents/IC")
data_mat = read.table("./neurips/data/docword_nips.txt", skip = 3)
head(data_mat[,c(2,1,3)])
str(data_mat)
data_mat = data_mat[,c(2,1,3)]
colnames(data_mat) = c("word", "doc", "freq")
data_mat = data_mat[-1,]
data = data_mat[order(data_mat[,2], decreasing=FALSE), ]
data_mat = as.matrix(data_mat)
# load mcmc chain
load(file = "./neurips/mcmc_output/mcmc_chain_10.Rdata")
# extracts marginal chains
beta_chain = chain$beta
chain$beta = 0
theta_chain = chain$theta
chain$theta = 0
mcmc_ind = 500:2000
# Defining variables
K = 10
D = max(data_mat$doc)
V = max(data_mat$word)
plot( beta_chain[1,1, ], type = "l" )
V = max(data_mat$word)
D = max(data_mat$doc)
type(data_mat)
typeof(data_mat)
load("~/IC/neurips/mcmc_output/mcmc_chain_10.Rdata")
# set working directory to the location of the main github folder in local machine
setwd("C:/Users/joaov/Documents/IC")
data_mat = read.table("./neurips/data/docword_nips.txt", skip = 3)
colnames(data_mat) = c("doc", "word", "freq")
head(data_mat[,c(2,1,3)])
str(data_mat)
data_mat = data_mat[,c(2,1,3)]
# data_mat = data_mat[-1,] <-------- NAO DELETE A PRIMEIRA LINHA. ELA PODE PERMANECER SEM PROBLEMAS
data = data_mat[order(data_mat[,2], decreasing=FALSE), ]
setwd("./codes")
source("utils.R")
sourceCpp("./mcmc_function.cpp")
source("./mcmc_bbc_function.R")
w = transform(data)
# Defining variables
K = 10
D = max(data_mat$doc)
V = max(data_mat$word)
# extracts marginal chains
beta_chain = chain$beta
chain$beta = 0
theta_chain = chain$theta
chain$theta = 0
mcmc_ind = 500:2000
plot( beta_chain[1,1, ], type = "l" )
plot( beta_chain[1,2, ], type = "l" )
plot( beta_chain[1,3, ], type = "l" )
plot( theta_chain[1,1, ], type = "l" )
plot( theta_chain[1,2, ], type = "l" )
plot( theta_chain[1,3, ], type = "l" )
hist(beta_chain[1,3,], freq = FALSE)
hist(beta_chain[1,4,mcmc_ind], freq = FALSE)
plot( beta_chain[1,4, ], type = "l" )
beta_chain[1,3,]
new_beta = beta_chain[,,mcmc_ind]
new_theta = theta_chain[,,mcmc_ind]
hist(new_theta[1,1,])
hist(new_theta[1,2,])
hist(new_theta[1,3,])
hist(new_theta[1,4,])
hist(new_theta[1,5,])
median(new_theta[1,1,])
median(new_theta[1,2,])
median(new_theta[1,3,])
median(new_theta[1,4,])
median(new_theta[1,5,])
median(beta_chain[1,1,])
####
v = c(3,4,5,6, 1, 2)
order(v, decreasing = TRUE)
v[order(v, decreasing = TRUE)]
####
median(beta_chain[1,3,mcmc_ind])
mean(beta_chain[1,1,mcmc_ind])
# Matriz de palavras por tópico
# do 1 at? o V, 2 at? o V, 3 at? o V ...
#usando o for no beta_chain
#comentar o z_chain e a parte da itera??o do z chain
beta_matrix = matrix(0,K,V)
for (k in 1: K){
for (v in 1:V){
beta_matrix[k,v] = mean(beta_chain[k,v,mcmc_ind])
}
}
words <- as.matrix(read.table("./neurips/data/nips_vocab.txt"))[,1]
words <- as.matrix(read.table("./neurips/data/nips_vocab.txt"))[,1]
getwd()
words <- as.matrix(read.table("C:/Users/joaov/Documents/IC/neurips/data/nips_vocab.txt"))[,1]
sort_index<- order(beta_matrix[1,],decreasing = TRUE)
beta_matrix[1,sort_index]
sort_index <- sort_index[1:10]
words[sort_index[1:10]]
T = 1
topics_matrix = matrix("0",10,K)
while (T<= K) {
sort_index <- order(beta_matrix[T,], decreasing = TRUE)
sort_index <- sort_index[1:K]
topics_matrix[,T] <- words[sort_index]
T = T+1
}
topics_matrix
DIC_LDA(data_mat = data_mat,chain = chain,mcmc_ind = 500:2000)
DIC_LDA(data_mat = data_mat,chain = chain,mcmc_ind = 500:1500)
